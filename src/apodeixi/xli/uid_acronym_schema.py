
# To avoid circular dependencies, we had to move this import to the very few functions in this module that need
# ManifestUtils
#from apodeixi.knowledge_base.manifest_utils        import ManifestUtils

from apodeixi.xli.uid_store                         import UID_Utils
from apodeixi.xli.interval                          import Interval
from apodeixi.util.a6i_error                        import ApodeixiError

class AcronymInfo():
    '''
    Helper data structure class. It packages information about an acronym that is needed by the algorithms
    of that manipulate, create, infer, abbreviate or unabbreviate UIDs.
    '''
    def __init__(self, acronym, entity_name):
        self.acronym            = acronym
        self.entity_name        = entity_name

    def copy(self):
        new_info        = AcronymInfo(  acronym         = self.acronym,
                                            entity_name     = self.entity_name)
        return new_info 

    def __key(self):
        return (self.acronym, self.entity_name)

    def __hash__(self):
        return hash(self.__key())

    def __eq__(self, other):
        if isinstance(other, AcronymInfo):
            return self.__key() == other.__key()
        return NotImplemented

    def __str__(self):
        return str(self.acronym) + " (" + str(self.entity_name) + ")"

class UID_Acronym_Schema():
    '''
    Class defining the schema of a manifest from the acronym perspective.

    This is logically represented as an ordered list of AcronymInfo objects. Such a list can be generated in two different ways:

    * During posting cycles (i.e., Excel files are being read), it can be generated from a list of intervals. The order of
      the intervals establishes the order of the AcronymInfo objects in the schema.

    * During generation cycles (i.e., an Excel file is being generated from a manifest_dict), it can be generated by an algorithm
      that traverses the manifest_dict to read the UID and entity fields in the tree represented by the manifest_dict.
    '''
    def __init__(self):
        self.acronyminfo_list       = [] # This is populated later by the build_schema* methods
        # To avoid circular dependencies, we had to move this import to the very few functions in this module that need
        # ManifestUtils
        from apodeixi.knowledge_base.manifest_utils import ManifestUtils
        self.MU                     = ManifestUtils()
        return

    def __str__(self):
        str_list    = [str(info) for info in self.acronyminfo_list]
        return str(str_list)

    def acronym_infos(self):
        return self.acronyminfo_list

    def schema_info_for_UID(self, parent_trace, a_uid):
        '''
        Returns a pair:

        * An AcronymInfo object representing the schema properties corresponsing to the given UID `a_uid`
        * A string corresponding to the name of the UID column that should be used in a DataFrame or Excel representation
          for that `a_uid`. Typically these strings are like "UID", "UID-1", "UID-2", etc.

        @param a_uid A string representing a UID. It may be a full UID like "BR3.MR2.SR1" or just a leaf UID like "SR1".

        '''
        leaf_uid                    = a_uid.split(".")[-1]
        acronym                     = UID_Utils().parseToken(parent_trace, leaf_uid)[0]
        acronyminfo_guesses         = [info for info in self.acronyminfo_list if info.acronym == acronym]
        if len(acronyminfo_guesses) != 1:
            raise ApodeixiError(parent_trace, "UID Acronym schema is either not initialized or corrupted: "
                                        " it does not recognize a unique acronym for entity's UID",
                                            data = {"entity_UID": str(leaf_uid),
                                                    "inferred acronyms": str(self.acronyminfo_list)})
        acronyminfo                 = acronyminfo_guesses[0]
        level                       = self.acronyminfo_list.index(acronyminfo)
        UID                         = Interval.UID
        if level==0:
            UID_COL                 = UID
        else:
            UID_COL                 = UID + '-' + str(level) # We start at "UID-1", "UID-2", etc. "UID" is on  

        return acronyminfo, UID_COL

    def build_schema_from_intervals(self, parent_trace, parser, interval_list):
        '''
        This method is intended to be used when parsing Excel files as part of the process of generating manifests.

        @param parser An instance of the BreakdownTree class. This must be the instance that is parsing Excel files, and
                    whose state is relied upon by this method to correctly create the schema.
        @param interval_list A list of Interval objects
        '''
        result                      = []
        for interval in interval_list:
            entity_name             = interval.entity_name
            acronym                 = parser.getAcronym(parent_trace, entity_name)
            result.append(AcronymInfo(acronym, entity_name))

        self.acronyminfo_list       = result

    def build_schema_from_manifest(self, parent_trace, manifest_dict):
        '''
        This method is intended to be used when generating Excel files.

        See documentation of self.build_schema_from_manifest_content, to which this method delegates
        '''
        entity                          = self.MU.infer_entity( parent_trace        = parent_trace, 
                                                                        manifest_dict       = manifest_dict, 
                                                                        manifest_nickname   = "Some manifest")
        contents_path                   = 'assertion.' + entity
        assertion_dict                  = manifest_dict['assertion']
        content_dict                    = assertion_dict[entity]
        self.build_schema_from_manifest_content(parent_trace, content_dict, parent_path = contents_path)

    def build_schema_from_manifest_content(self, parent_trace, content_dict, parent_path):
        '''
        This method is intended to be used when generating Excel files.

        It inspects the manifest's contents (the `content_dict`), and based on that the acronym schema is
        constructed.

        Implementation notes:

        The algorithm used requires first doing a full pass through the whole "tree" (looking at `content_dict` as a tree)
        because local inference would be buggy. It would lead to the wrong UID columns being defined in the DataFrame.
        
        Example:
        
        Consider a path in `content_dict` involving these UIDs: A1, A1.I1, A1.II.AS1.

        If we inferred level-based UID column names from these, we might think that A1 corresponds to "UID", that
        A1.I1 corresponds to "UID-1", and that A1.I1.AS1 corresponds to "UID-2".

        However, such an algorithm was found to be buggy in real life, which is why this class AcronymSchema is needed.

        This example exhibits the bug. Consider we are supposed to create a DataFrame like this, where every column
        is an entity:

               Area |  Indicator        |  Sub Indicator    | Applicable Space
            ====================================================================
             Adopt  |  %containeraized  |                   | Components
                    |  %testing         | Functional Tests  | Scenarios.functional
                    |                   | Performance Tests | 
 

        In this example there are 4 acronyms: A (for Area), I (for Indicator), SI (for Sub Indicator), and
        AS (for Applicable Area)

        The first row has no SubIndicator, so the leaf entity would get a full UID of A1.I1.AS1, whereas the other
        two paths (i.e., rows) would get full UIDs of A1.I2.SI1.AS1 and A1.I2.SI2

        If we assigned level-based UID column names, we would incorrectly use UID-2 for the interval
        [Applicable Space] in row1, and use UID-2 for a different interval [Sub Indicator] for the other two rows.

        This would be a bug, that would corrupt the DataFrame constructed by this class. When this bug was found, the
        effect was that the DataFrame sported "UID-2" appearing as two separate columns, causing errors downstream in code
        that assumed that each column name was unique.

        So to fix this problem, this method does a pass through the entire `content_dict` to get a a "schema", basically
        an object that logially represents list of acronyms (and entities, not shown here), in this example would be:

            ["A", "I", SI", "AS"]

        That way other Apodexi processing code can use methods like self.schema_info_for_UID when finding out 
        the leveled-UID column name to use for an full UID. 

        The implementation of this methods is in two passes (sort of a map-reduce)

        * First pass is recursive, going through the `content_dict` and getting a list of lists, one for each path.
          In our example that would produce (notice not all acronyms appear in all lists, and in some cases may
          not all appear in even 1 list)

            [ ["A", "I", "AS"], ["A", "I", SI", "AS"], ["A", "I", SI"]]

        * Second pass then reduces this to a single list that has the property that it includes all acronyms listed
          in any of the lists in the first pass, in the same order. In the example, that is ["A", "I", SI", "AS"]
        '''
        # all_acronyms_list is a list of lists of _AcronymInfo objects
        all_acronym_info_lists          = self._map_acronyminfo_lists(parent_trace, content_dict, parent_path, parent_uid=None)

        # Now the "reduce" phase
        result                          = []
        working_acronyminfo_lists       = all_acronym_info_lists.copy()
        MAX_LOOPS                       = 1000 # To avoid inadvertent infinite loops if there is a bug in the logic in the loop
        loop_nb                         = 0
        while loop_nb < MAX_LOOPS and len(working_acronyminfo_lists) > 0:
            loop_trace                  = parent_trace.doing("Determining next acronym to append to the acronyms list",
                                            data = {"result so far":        str(result), 
                                                    "pending to explore":   str(working_acronyminfo_lists)})
            first_acronyminfo           = self._find_first_acronyminfo(loop_trace, working_acronyminfo_lists)
            if not first_acronyminfo in result:
                result.append(first_acronyminfo)
            next_working_lists          = []
            for a_list in working_acronyminfo_lists:
                if first_acronyminfo in a_list:
                    modified_list       = a_list.copy()
                    modified_list.remove(first_acronyminfo)
                    if len(modified_list) > 0:
                        next_working_lists.append(modified_list)
                else:
                    next_working_lists.append(a_list)
            # Initialize state for next cycle in loop
            loop_nb                     += 1
            working_acronyminfo_lists   = next_working_lists

        self.acronyminfo_list           = result

    def find_entity(self, parent_trace, content_dict):
        '''
        Finds the a unique entity for `content_dict`, defined as unique child that is a dictionary and not
        a scalar.

        If it is found, returns a string with that entity name.
        If none is found it returns None.

        In the eventuality that there are multipe children of the dictionary that are also dictionaries, it
        raises an ApodeixiError.
        
        '''
        # Apodeixi's data model allows "multiple dimensional" branching. An example of branching is having
        # a "big-rock" entity "BR1" branch into multiple "Sub rock" entities "BR1.SR1", "BR1.SR2", "BR1.SR3", ...
        # "Multi-dimensional" branching happens if the "big-rock" entity can also branch into another
        # entity like "Epic", leading to children like "BR1.E1", "BR1.E2", "BR1.E3", ...

        # While that is allowed in the data model, it is not possible to represent such multi-dimensional
        # branching neatly in a tabular representation like a DataFrame, which is what this schema class
        # is representing.
        #
        # So since this method is about creating such tabular representation, we will error out if we find that
        # "multi-dimensional" branching occurs in the manifest.
        sub_entities                    = []
        for k in content_dict.keys():
            child                       = content_dict[k]
            if type(child) == dict:
                sub_entities.append(k)

        if len(sub_entities) == 0:
            return None
        elif len(sub_entities) > 1:
            raise ApodeixiError(parent_trace, "At most one sub entity is allowed when representing a manifest as as "
                                            + " DataFrame, but found several: " 
                                + sub_entities)
        else:
            return sub_entities[0]

    def _find_first_acronyminfo(self, parent_trace, all_acronyminfo_lists):
        '''
        This is a helper method to the "reduce" phase of the algorithm used by method _find_acronym_list.
        Refer to the documenation of that method for an explanation of the context for the algorithm.

        The particular contribution of this method is to identify the first acronym that should be used.
        This algorithm requires that there one unique such, meeting these conditions:
        
        * It appears in at least on list
        * If it appears in a list at all, it appears first
        * It is the unique such

        It returns the result as an _AcronymInfo object

        @param all_acronyminfo_list A list of lists, where inner lists contains _AcronymInfo objects
        '''
        candidates              = [a_list[0] for a_list in all_acronyminfo_lists if len(a_list) > 0]
        # Remove duplicates, if any
        candidates              = list(set(candidates))

        # Disqualify any candidate if it is not first in at least one of the lists
        disqualified            = [acronyminfo for acronyminfo in candidates 
                                        if max([a_list.index(acronyminfo) for a_list 
                                                in all_acronyminfo_lists if acronyminfo in a_list]) > 0]
        qualified               = [acronyminfo for acronyminfo in candidates if acronyminfo not in disqualified]
        if len(qualified) == 0:
            raise ApodeixiError(parent_trace, "Badly formed acronyms list: there is no acronym that occurs only first in the "
                                                + "lists where it appears",        
                                    data = {"all_acronyms_list": str(all_acronyminfo_lists)})
        if len(qualified) > 1:
            raise ApodeixiError(parent_trace, "Badly formed acronyms list: there are multiple acronyms competing to be "
                                                + "the first acrony",        
                                    data = {"all_acronyms_list": str(all_acronyminfo_lists),
                                            "competing acronyms": str(qualified)})
        # If we get this far we are in good shape. There is a unique qualified candidate, so return it
        return qualified[0]

    def _map_acronyminfo_lists(self, parent_trace, content_dict, parent_path, parent_uid):
        '''
        This is a recursive helper method to the "map-reduce" algorithm used by method _find_acronym_list. 
        Refer to the documentation of that method for an explanation of the context for the algorithm.

        This method returns a list of lists, where the inner list consist of _AcronymInfo objects.
        '''
        my_trace                = parent_trace.doing("Mapping acronym lists for '" + parent_path + "''",
                                                        data = {'signaledFrom': __file__})
        if True:
            if parent_path == None or len(parent_path.strip()) == 0:
                raise ApodeixiError(my_trace, "Can't process a parent_path that is null or blank")

        # parent_path is something like "assertion.big-rock" when this method is first called, and 
        # like  "assertion.big-rock.BR1.Sub rock" when this method is calls recursively on itself
        path_tokens             = parent_path.split('.') 
        entity_name             = path_tokens[-1] # like "big-rock" on 1st call, and "Sub rock" on recursive call 

        entity_uids             = [key for key in content_dict.keys() if not key.endswith('-name')]

        # Will be one per "path" within the "tree" represented by `content_dict`, consisting of the acronyms
        # encountered along that path, in order.
        all_acronyms_result     = [] 
                    
        my_trace                = parent_trace.doing("Mapping acronyms under of '" + str(parent_path) + "'",
                                                        data = {'signaledFrom': __file__})

        
        # On a first call we loop through something like e_uid = "BR1", "BR2", "BR3", .... For that call
        #       parent_uid = None and parent_path = "assertion.big-rock"
        # On a recursive call with parent_uid = "BR1" we loop through e_uid = "SR1", "SR2", "SR3", .... In this case
        #       parent_path = "assertion.big-rock.BR1.Sub rock"
        for e_uid in entity_uids:
            loop_trace          = parent_trace.doing("Looping on entity with UID '" + str(e_uid) + "'",
                                                    data = {'signaledFrom': __file__})
            if parent_uid == None:
                full_e_uid      = e_uid
            else:
                full_e_uid      = parent_uid + '.' + e_uid
                
            e_acronym           = UID_Utils().parseToken(loop_trace, e_uid)[0]

            e_path              = parent_path  + '.' + e_uid

            e_dict              = content_dict[e_uid]

            inner_trace         = loop_trace.doing("Checking tree under '" + e_path + "' is well formed",
                                            data = {'signaledFrom': __file__})
            if True:
                # Check e.g. if content_dict = manifest_dict["assertion"]["big-rock"]["BR1"]["SubRock"]
                # and e_uid = "SR2", that content_dict["SR2"] exists and is a dictionary
                if e_dict == None:
                    raise ApodeixiError(inner_trace, "Badly formatted tree: found nothing under '" + e_path + "'")
                if type(e_dict) != dict:
                    raise ApodeixiError(inner_trace, "Badly formatted tree: expected dictionary at '" + e_path
                                                       + "' but instead found a " + str(type(e_dict)))

            inner_trace         = loop_trace.doing("Getting acronym lists under '" + e_path + "'",
                                            data = {'signaledFrom': __file__})
            sub_entity          = self.find_entity(inner_trace, e_dict) # Something like "Sub rock"
            # Now we gear up to make a recursive call. For example, if we have been processing the interval
            # ["UID", "big-rock"] and e_dict = content_df["BR1"], we are now going to take the plunge into
            # the unique sub-entity "Sub rock" and make a recursive call to process interval
            # ["UID-1", "Sub rock"] passing content_df["BR1"]["Sub rock"] as the content to process.
            #
            # For our e_path = "assertion"."big-rock"."BR1" we pass a path of "assertion"."big-rock"."BR1"."Sub rock"
            # we set "ourselves" ("BR1") as the parent_uid in the recursive call
            if sub_entity == None:
                acronyms_list               = [AcronymInfo(e_acronym, entity_name)]
                all_acronyms_result.append(acronyms_list)
            else:
                inner_trace                 = loop_trace.doing("Making a recursive call for '" + sub_entity + "'",
                                                                data = {'signaledFrom': __file__})

                acronyms_subresult          = self._map_acronyminfo_lists   (parent_trace    = inner_trace, 
                                                                        content_dict    = e_dict[sub_entity], 
                                                                        parent_path     = e_path + '.' + sub_entity,
                                                                        parent_uid      = full_e_uid)
                for acronyms_sublist in acronyms_subresult:
                    # Check we are not about to put duplicate acronyms - if so, that is an error with the `content_df`
                    if e_acronym in acronyms_sublist:
                        raise ApodeixiError(inner_trace, "Looks like manifest is corrupted because the same acronym is "
                                                    + " used at different levels. An acronym should be used in only 1 level",
                                                    data = {"Problem at UID": str(full_e_uid),
                                                            "Acronyms below UID": str(acronyms_sublist)})
                    acronyms_list           = [AcronymInfo(e_acronym, entity_name)]
                    acronyms_list.extend(acronyms_sublist)
                    all_acronyms_result.append(acronyms_list)

        return all_acronyms_result
                

